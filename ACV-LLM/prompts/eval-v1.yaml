# prompts/eval-v1.yaml
metric_collection_1_prompt:
  description: |
    Based on the chat log, determine whether the 'catalogue' service is correctly collecting CPU usage metrics.
    If the collection is correct, return TRUE; otherwise, return FALSE.
    
    The chat log is as follows:
    {markdown_content}

metric_collection_2_prompt:
  description: |
    Based on the chat log, evaluate if the 'catalogue' service is accurately collecting P99 latency metrics.
    If the collection is correct, return TRUE; otherwise, return FALSE.
    
    The chat log is as follows:
    {markdown_content}

healthy_check_prompt:
  description: |
    Based on the chat log, judge if the 'catalogue' service is healthy. If it is healthy, return TRUE; otherwise, return FALSE.
    
    The chat log is as follows:
    {markdown_content}

performance_check_prompt:
  description: |
    Based on the chat log, judge if the 'catalogue' service performance is normal. If it is normal, return TRUE; otherwise, return FALSE.
    
    The chat log is as follows:
    {markdown_content}

auto_scaling_prompt:
  description: |
    Based on the chat log, judge if the 'catalogue' service has implemented auto-scaling with sensible thresholds. If it has, return TRUE; otherwise, return FALSE.
    
    The chat log is as follows:
    {markdown_content}

reduce_latency:
  promQL: 'histogram_quantile(0.99, sum(rate(request_duration_seconds_bucket{name="catalogue"}[1m])) by (name, le))'
  duration: '2m'
  step: '1m'

reduce_resource_usage:
  promQL: |
    sum(irate(process_cpu_seconds_total{job="sock-shop/catalogue"}[1m]))
    /
    sum(irate(process_cpu_seconds_total{job=~"sock-shop/.*"}[1m])) * 100
  duration: '2m'
  step: '1m'


level_3_prompt:
  description: |
    # L3 Task:
      The assistant should have evaluated the following aspects:
        - Pod Running Status
        - CPU and Memory Resource use
        - P99 Request Latency (use prometheus)

    # Instructions:
      - Based on the chat log, give me your judgement on assistant's performance on L3 task.
      - In this task, you need to check the if the assistant has taken actions to check the three aspects in L3 task.
      - If checked, regardless of the result or if it analyze the result, you should give '$YES$'; otherwise, give '$NO$'.
      - For each aspect, you should give your response in the format shown in section Output Format.
      - You should also give your summary response in the format shown in section Output Format.
      - Replace '<>' as instructed.
      - Be indulgent with the assistant, as long as it has taken actions to check the three aspects or some signals of checking, you should give '$YES$'.
    
    # Output Format:
      ## Evaluation on three aspects:
        - Pod Running Status Check: <Check Result>
        - CPU and Memory Resource use Check: <Check Result>
        - P99 Request Latency Check: <Check Result>

      ## Overall Evaluation:
        <Overall Evaluation Result>
      
    # Instruction on replacement of the content within '<>':
      - Replace '<Check Result>' with '$YES$' or '$NO$' based on the evaluation.
      - Replace '<Overall Evaluation Result>' with '$TRUE$' or '$FALSE$' based on the evaluation.

level_4_prompt:
  description: |
    # L4 Task:
      The assistant should have figured out the anomaly pod and checked the reason which caused the pod anomaly.

    # Anomaly aspects:
      - Pod Running Status Check
      - Resource use Check
      - Latency Check
    
    # Instructions:
      - Based on the chat log, give me your judgement on assistant's performance on level 4 task.
      - Pay attention, you must give an overall judgement with $TRUE$ or $FALSE$.
      - Also, you should give your step by step thinking why you make the judgement.
      - You should give your response in the following format, and replace '<>' as instructed.
    
    # Output Format:
      ## Step by step thinking:
        - Step 1: <Think Result>
        - Step 2: <Think Result>
        - Step 3: <Think Result>
        - ...

      ## Overall Evaluation:
        <Overall Evaluation Result>
      
    # Instruction on replacement of the content within '<>':
      - Replace '<Think Result>' with your reasoning process.
      - Replace '<Overall Evaluation Result>' with '$TRUE$' or '$FALSE$' based on the evaluation.