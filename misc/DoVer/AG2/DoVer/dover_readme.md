# DoVer Scripts Usage Guide

This note explains how to run the log decomposition and trial summarization helpers under `DoVer/scripts`, including required inputs and produced artifacts.

## Prerequisites
- Python 3.10 or later available on the path as `python`.
- Azure OpenAI credentials available via `AZURE_OPENAI_ENDPOINT` + `AZURE_OPENAI_API_KEY` (optional `AZURE_OPENAI_API_VERSION`, default `2024-08-01-preview`).
- Experiment directory layout: each scenario resides in `<exp_results_dir>/<scenario>/` and must contain:
  - `chat_history.json` - raw chronological agent dialogue.
  - `session_metadata.json` - provides `problem_text` and `ground_truth`.

After you run `log_decomposer.py`, the same folder will also contain `chat_history_with_index.json` and `plan_step.json`, which are required by the trial summarizer.

## Log Decomposition (`log_decomposer.py`)
```bash
python DoVer/scripts/log_decomposer.py --exp_results_dir experiments/test_output --scenario 018efed1-9951-5512-a991-d2115e718547
```
- **Inputs**: `chat_history.json`, `session_metadata.json`.
- **Outputs**:
  - `chat_history_with_index.json` - adds a `step_idx` to every message.
  - `plan_step.json` - records the initial plan and `plan_update_steps` (the script prints the saved path).
- Handy flags: `--hist_path` (custom chat log), `--azure-endpoint`, `--api-key`, `--api-version`, `--model`, `--max-tokens`, `--dataset_name` (currently limited to `GSMPlus`).

### Batch decomposition (`batch_log_decomposer.py`)
```bash
python DoVer/scripts/batch_log_decomposer.py --exp_results_dir experiments/test_output --dry-run
```
- Lists all scenarios that contain `chat_history.json`; remove `--dry-run` to process them sequentially.
- Optional extras: `--output-summary <path>` to write a JSON report, `-v/--verbose` for additional logging, `--no-progress` to disable the progress bar.

## Trial Summarization (`trial_summarizer.py`)
```bash
python DoVer/scripts/trial_summarizer.py --exp_results_dir experiments/test_output --scenario fe9a1fc1-20e9-5e02-bc4a-4d56f3b205ea
```
- **Inputs**: `chat_history_with_index.json`, `plan_step.json`, `session_metadata.json`.
- **Output**: `trial_summary.json` in the scenario directory summarizing each trial's plan, execution, success flag, and mistake diagnosis (path echoed to stdout).
- Flags mirror the decomposer; `--dataset_name` must remain `GSMPlus`.

### Batch summarization (`batch_trial_summarizer.py`)
```bash
python DoVer/scripts/batch_trial_summarizer.py --exp_results_dir experiments/test_output --dry-run
```
- Processes only scenarios that already include both `chat_history_with_index.json` and `plan_step.json`.
- Supports `--output-summary`, `-v/--verbose`, and `--no-progress`; drop `--dry-run` to execute all runs.

## Intervention Recommendation (`intervention_recommender_trial.py`)
```bash
python DoVer/scripts/intervention_recommender_trial.py --exp_results_dir experiments/test_output --scenario fe9a1fc1-20e9-5e02-bc4a-4d56f3b205ea
```
- **Purpose**: converts `trial_summary.json` into targeted interventions for each failed trial.
- **Inputs**: `trial_summary.json`, `chat_history_with_index.json` (falls back to `chat_history.json`), and the dataset metadata loaded via `load_problem_gt`.
- **Output**: `intervention_recommendation.json` (or the custom path passed via `--output`), containing one object per failed trial with a `replacement_text` field (the rewritten agent message) plus the raw model response for auditing.
- Key flags: `--azure-endpoint`, `--api-key`, `--api-version`, `--model`, and `--max-tokens` control the Azure OpenAI endpoint; `--dataset_name` is restricted to `GSMPlus`/`Olympiad` for compatibility with `load_problem_gt`.
- Skip trials already marked as successful in `trial_summary.json`; only failed trials with valid `mistake_step_index` values are processed.

## Checkpoint Continuation (`intervener_trial.py`)
```bash
python DoVer/scripts/intervener_trial.py --exp_results_dir experiments/test_output --scenario fe9a1fc1-20e9-5e02-bc4a-4d56f3b205ea --max_rounds 8
```
- **Purpose**: applies the interventions from `intervention_recommendation.json`, patches the corresponding checkpoints, and resumes the AG2 conversation to validate fixes.
- **Inputs**: `intervention_recommendation.json`, `chat_history_with_index.json` (or `chat_history.json`), and the original `checkpoints/checkpoint_*_message_appended_*.json` artifacts generated by the checkpoint manager.
- **Outputs**:
  - `trial_<index>/patched_checkpoint_step<step>.json` containing the modified checkpoint per intervention.
  - `trial_<index>/continuation/continuation_summary.json` summarizing the resumed run (success flag, termination reason, message counts, paths to the original and patched checkpoints).
  - `trial_<index>/continuation/chat_history_with_index.json` capturing the updated conversation with freshly generated messages appended.
  - A JSON array printed to stdout, listing each processed intervention with the resolved checkpoint path, continuation directory, and bookkeeping fields such as `message_index` and `trial_dir`.
- Set `--max_rounds` to bound the number of additional turns executed after resuming; the script reads `AZURE_OPENAI_ENDPOINT`, `AZURE_OPENAI_API_KEY`, and (optionally) `AZURE_OPENAI_API_VERSION` when recreating the manager.
- If a required checkpoint or intervention entry is missing, the script raises an error indicating the offending step.

## Recommended Flow
1. Place raw chat logs and metadata under `<exp_results_dir>/<scenario>/`.
2. Run `log_decomposer.py` (or the batch helper) to generate planning checkpoints.
3. Run `trial_summarizer.py` (or its batch variant) to produce trial reports.
4. Run `intervention_recommender_trial.py` to draft intervention candidates for each failed trial (optionally overriding `--output` for custom storage).
5. Use `intervener_trial.py` to replay checkpoints with those interventions and capture continuation transcripts.
6. Inspect `plan_step.json`, `trial_summary.json`, and the continuation artifacts for evaluation or reporting.

If a script reports missing files, double-check the scenario folder contents. If the model returns invalid JSON, review your Azure credentials, quota, and model parameters.
